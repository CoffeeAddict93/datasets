# RateMyProfessors aggregate data

From [supplementary material](https://www.tandfonline.com/doi/suppl/10.1080/02602938.2016.1276155) of:

Andrew S Rosen (2018) "Correlations, trends and potential biases among
publicly accessible web-based student evaluations of teaching:
a large-scale study of RateMyProfessors.com data" *Assessment
& Evaluation in Higher Education* 43(1) pp 31-44.
<https://doi.org/10.1080/02602938.2016.1276155>

There is a [freely available post
print](https://asrosen.com/wp-content/uploads/2018/07/postprint_rmp-1.pdf) on
[Andrew Rosen's website](https://asrosen.com).

The paper studies ratings from RateMyProfessors.com, for the 190,006 US
professors that have at least 20 student ratings.

Each row of the data table gives the mean ratings for all professors in a given discipline; thus there is one row per discipline.

Quoting from the paper above:

> Students on RateMyProfessors rate professors based on three main key
> criteria: clarity, helpfulness, and easiness. These criteria are mandatory
> fields when a review is submitted, and the rating scale ranges from 1 to 5 in
> integer increments with 1 being the worst rating and 5 being the best rating.
> Professors are then assigned an overall quality score that is simply the
> average of their clarity and helpfulness scores.

Given that background, the column names are self-explanatory:

* Discipline
* Number of Professors
* Clarity
* Helpfulness
* Overall Quality
* Easiness
